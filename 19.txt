1.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Load the Salary_positions dataset (assuming a CSV file with 'Level' and 'Salary')
# Example dataset creation (replace this with your actual dataset)
data = {
    'Level': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Salary': [45000, 50000, 60000, 65000, 70000, 80000, 85000, 90000, 95000, 100000]
}
df = pd.DataFrame(data)

# Prepare the feature matrix X and target variable y
X = df[['Level']].values  # Level is the feature
y = df['Salary'].values   # Salary is the target variable

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 1. Simple Linear Regression Model
simple_lr = LinearRegression()
simple_lr.fit(X_train, y_train)
y_pred_simple = simple_lr.predict(X_test)

# Evaluate Simple Linear Regression
mse_simple = mean_squared_error(y_test, y_pred_simple)
r2_simple = r2_score(y_test, y_pred_simple)

print(f"Simple Linear Regression:")
print(f"Mean Squared Error: {mse_simple:.2f}")
print(f"R-squared: {r2_simple:.2f}")

# 2. Polynomial Linear Regression Model (Degree = 2 for this example)
poly = PolynomialFeatures(degree=2)
X_poly_train = poly.fit_transform(X_train)
X_poly_test = poly.transform(X_test)

poly_lr = LinearRegression()
poly_lr.fit(X_poly_train, y_train)
y_pred_poly = poly_lr.predict(X_poly_test)

# Evaluate Polynomial Linear Regression
mse_poly = mean_squared_error(y_test, y_pred_poly)
r2_poly = r2_score(y_test, y_pred_poly)

print(f"\nPolynomial Linear Regression:")
print(f"Mean Squared Error: {mse_poly:.2f}")
print(f"R-squared: {r2_poly:.2f}")

# Predict the salaries for level 11 and level 12 using both models
level_11 = np.array([[11]])
level_12 = np.array([[12]])

# Simple Linear Regression Prediction
salary_11_simple = simple_lr.predict(level_11)
salary_12_simple = simple_lr.predict(level_12)

# Polynomial Linear Regression Prediction
salary_11_poly = poly_lr.predict(poly.transform(level_11))
salary_12_poly = poly_lr.predict(poly.transform(level_12))

print(f"\nPredicted Salary for Level 11 (Simple LR): ${salary_11_simple[0]:,.2f}")
print(f"Predicted Salary for Level 12 (Simple LR): ${salary_12_simple[0]:,.2f}")
print(f"Predicted Salary for Level 11 (Polynomial LR): ${salary_11_poly[0]:,.2f}")
print(f"Predicted Salary for Level 12 (Polynomial LR): ${salary_12_poly[0]:,.2f}")

# Visualizing the results
plt.scatter(X, y, color='red')  # Scatter plot of original data
plt.plot(X, simple_lr.predict(X), color='blue', label="Simple Linear Regression")
plt.plot(X, poly_lr.predict(poly.transform(X)), color='green', label="Polynomial Linear Regression")
plt.title("Simple vs Polynomial Linear Regression")
plt.xlabel("Position Level")
plt.ylabel("Salary")
plt.legend()
plt.show()

2
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

# Sample weather forecast dataset (replace this with your actual dataset)
data = {
    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Rainy', 'Overcast', 'Sunny', 'Sunny', 'Rainy'],
    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Mild', 'Mild', 'Cool', 'Mild'],
    'Humidity': ['High', 'High', 'High', 'High', 'Low', 'Low', 'Low', 'High', 'Low', 'Low'],
    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong', 'Weak'],
    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes']
}

df = pd.DataFrame(data)

# Convert categorical data into numerical values using LabelEncoder
label_encoder = LabelEncoder()
df['Outlook'] = label_encoder.fit_transform(df['Outlook'])
df['Temperature'] = label_encoder.fit_transform(df['Temperature'])
df['Humidity'] = label_encoder.fit_transform(df['Humidity'])
df['Wind'] = label_encoder.fit_transform(df['Wind'])
df['PlayTennis'] = label_encoder.fit_transform(df['PlayTennis'])

# Prepare feature matrix X and target variable y
X = df.drop('PlayTennis', axis=1)
y = df['PlayTennis']

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Naive Bayes classifier
nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)

# Predict on the test set
y_pred = nb_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of Naive Bayes model: {accuracy * 100:.2f}%")
