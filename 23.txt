1.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Load the dataset
df = pd.read_csv('Salary_positions.csv')

# Assuming the dataset has two columns: 'Level' (employee level) and 'Salary' (employee salary)
X = df[['Level']].values  # Independent variable (employee level)
y = df['Salary'].values   # Dependent variable (employee salary)

# Split the dataset into training and testing data (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 1. Simple Linear Regression Model
linear_regressor = LinearRegression()
linear_regressor.fit(X_train, y_train)

# Predicting using the simple linear regression model
y_pred_linear = linear_regressor.predict(X_test)

# Evaluate the model
mse_linear = mean_squared_error(y_test, y_pred_linear)
print(f"Mean Squared Error for Simple Linear Regression: {mse_linear:.2f}")

# 2. Polynomial Linear Regression Model
poly_features = PolynomialFeatures(degree=4)
X_poly = poly_features.fit_transform(X_train)

poly_regressor = LinearRegression()
poly_regressor.fit(X_poly, y_train)

# Predicting using the polynomial regression model
X_test_poly = poly_features.transform(X_test)
y_pred_poly = poly_regressor.predict(X_test_poly)

# Evaluate the polynomial regression model
mse_poly = mean_squared_error(y_test, y_pred_poly)
print(f"Mean Squared Error for Polynomial Linear Regression: {mse_poly:.2f}")

# Plotting the results for comparison
plt.scatter(X, y, color='blue')  # Actual data points
plt.plot(X, linear_regressor.predict(X), color='red', label='Linear Regression')  # Simple Linear Regression line
plt.plot(X, poly_regressor.predict(poly_features.fit_transform(X)), color='green', label='Polynomial Regression')  # Polynomial Regression curve
plt.title('Simple vs Polynomial Linear Regression')
plt.xlabel('Level')
plt.ylabel('Salary')
plt.legend()
plt.show()

# Predicting salaries for Level 11 and Level 12 employees using both models
level_11 = np.array([[11]])
level_12 = np.array([[12]])

# Simple Linear Regression predictions
pred_salary_11_linear = linear_regressor.predict(level_11)
pred_salary_12_linear = linear_regressor.predict(level_12)

# Polynomial Linear Regression predictions
pred_salary_11_poly = poly_regressor.predict(poly_features.transform(level_11))
pred_salary_12_poly = poly_regressor.predict(poly_features.transform(level_12))

print(f"Predicted salary for Level 11 employee (Linear): {pred_salary_11_linear[0]:.2f}")
print(f"Predicted salary for Level 12 employee (Linear): {pred_salary_12_linear[0]:.2f}")
print(f"Predicted salary for Level 11 employee (Polynomial): {pred_salary_11_poly[0]:.2f}")
print(f"Predicted salary for Level 12 employee (Polynomial): {pred_salary_12_poly[0]:.2f}")


2

import pandas as pd

# Create your own dataset (for demonstration purposes)
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', None],
    'Age': [25, 30, None, 22, 29],
    'Salary': [50000, 55000, 60000, None, 45000]
}

# Convert the dictionary into a pandas DataFrame
df = pd.DataFrame(data)

# Check for null values in the dataset
print("Null Values in the Dataset:")
print(df.isnull().sum())

# Drop rows with any null values
df_cleaned = df.dropna()

# Print the cleaned dataset
print("\nCleaned Dataset (rows with null values removed):")
print(df_cleaned)

# Alternatively, to drop columns with null values:
df_cleaned_columns = df.dropna(axis=1)
print("\nDataset with columns containing null values removed:")
print(df_cleaned_columns)
